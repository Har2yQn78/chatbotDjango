{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ed78f7-5dff-46ac-8651-98e35e4471c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "import os\n",
    "import numpy as np\n",
    "from decouple import config, AutoConfig\n",
    "config = AutoConfig(search_path=\"/home/harry/chatbotDjango\") \n",
    "\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c86d61c-c2d6-48dc-9591-51d8f155305a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from coffeshop.models import EmployeeRole, Employee, ProductType, Product, InventoryItem, ProductInventoryRequirement\n",
    "from coffeshop import services\n",
    "from llama_index.core.schema import TextNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb8b8dbf-928a-4446-b340-a6e2828f3e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.mistralai import MistralAI\n",
    "from llama_index.embeddings.mistralai import MistralAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fe2d406-c30a-4481-99d9-767b4923be92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mistralai import Mistral\n",
    "\n",
    "MISTRAL_API_KEY = config(\"MISTRAL_API_KEY\")\n",
    "\n",
    "EMEDDING_LENGTH=config(\"EMEDDING_LENGTH\", default=1024, cast=int)\n",
    "\n",
    "LLM_CONFIG = {\n",
    "    \"api_key\" : MISTRAL_API_KEY,\n",
    "}\n",
    "\n",
    "EMBED_CONFIG = {\n",
    "    \"api_key\" : MISTRAL_API_KEY,\n",
    "    \"model_name\" : \"mistral-embed\"\n",
    "}\n",
    "\n",
    "llm = MistralAI(**LLM_CONFIG)\n",
    "embed_model = MistralAIEmbedding(**EMBED_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "394bcf4c-d57a-413c-9ca4-a73c61cf1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba60056-2d72-4d9d-9430-a78a0506ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    EmployeeRole,\n",
    "    Employee,\n",
    "    ProductType,\n",
    "    Product,\n",
    "    InventoryItem,\n",
    "    ProductInventoryRequirement\n",
    "]\n",
    "\n",
    "table_names = [model.__name__.lower() + \"s\" for model in models]\n",
    "vector_db_name = \"vector_db\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52327879-03f3-4f3d-ab7e-db715c96200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config, AutoConfig\n",
    "config = AutoConfig(search_path=\"/home/harry/chatbotDjango\") \n",
    "DATABASE_URL = config(\"DATABASE_URL_POOL\")\n",
    "if DATABASE_URL.startswith(\"postgres://\"):\n",
    "    DATABASE_URL = DATABASE_URL.replace(\"postgres://\", \"postgresql://\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c964a5a-5cda-4799-885a-b5260eb18984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "engine = create_engine(DATABASE_URL, isolation_level=\"AUTOCOMMIT\")\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT 1 FROM pg_database WHERE datname = :db_name\"), {\"db_name\": vector_db_name})\n",
    "    db_exists = result.scalar() == 1\n",
    "    \n",
    "    if not db_exists:\n",
    "        connection.execute(text(\"CREATE EXTENSION IF NOT EXISTS vector WITH SCHEMA public\"))\n",
    "        connection.execute(text(f\"CREATE DATABASE {vector_db_name}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ef8361d-e4a0-4ac1-af7b-18c2f272d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import make_url\n",
    "from llama_index.vector_stores.postgres import PGVectorStore\n",
    "\n",
    "url = make_url(DATABASE_URL)\n",
    "vector_stores = {}\n",
    "\n",
    "for model, table_name in zip(models, table_names):\n",
    "    vector_store = PGVectorStore.from_params(\n",
    "        database=vector_db_name,\n",
    "        host=url.host,\n",
    "        password=url.password,\n",
    "        port=url.port or 5432,\n",
    "        user=url.username,\n",
    "        table_name=table_name,\n",
    "        embed_dim=EMEDDING_LENGTH,\n",
    "    )\n",
    "    vector_stores[model.__name__] = vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df0541da-cf28-47a2-89bd-98391753e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "indices = {}\n",
    "query_engines = {}\n",
    "\n",
    "for model, table_name in zip(models, table_names):\n",
    "    instances = model.objects.all()\n",
    "    \n",
    "    nodes = [\n",
    "        TextNode(\n",
    "            text=str(instance),\n",
    "            metadata={\n",
    "                \"model\": model.__name__,\n",
    "                \"id\": instance.id,\n",
    "                \"created_at\": instance.created_at.isoformat() if hasattr(instance, 'created_at') else None\n",
    "            }\n",
    "        ) for instance in instances\n",
    "    ]\n",
    "    \n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        vector_store=vector_stores[model.__name__]\n",
    "    )\n",
    "    indices[model.__name__] = VectorStoreIndex(\n",
    "        nodes, storage_context=storage_context\n",
    "    )\n",
    "    query_engines[model.__name__] = indices[model.__name__].as_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c0a930-06dd-4e99-90f4-8a699d7991ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Employee Roles Response: Empty Response\n",
      "Products Response: Empty Response\n"
     ]
    }
   ],
   "source": [
    "employee_role_response = query_engines[\"EmployeeRole\"].query(\n",
    "    \"List all employee roles and their permissions\"\n",
    ")\n",
    "print(f\"Employee Roles Response: {employee_role_response}\")\n",
    "\n",
    "product_response = query_engines[\"Product\"].query(\n",
    "    \"What are the top 5 most expensive products?\"\n",
    ")\n",
    "print(f\"Products Response: {product_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98383b29-03dd-4354-b17a-aefe66ac5dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
