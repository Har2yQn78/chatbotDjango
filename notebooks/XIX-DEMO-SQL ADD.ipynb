{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abc78c8f-5754-4744-bdc8-a407936de6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import setup\n",
    "\n",
    "setup.init_django()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98cd97d0-3b59-48a7-9fc6-28e5342a6992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rag import (\n",
    "    db as rag_db,\n",
    "    engines as rag_engines,\n",
    "    settings as rag_settings,\n",
    "    updaters as rag_updaters,\n",
    "    sync as rag_sync, \n",
    "    patches as rag_patches,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68499f9d-26d0-4cba-bf79-2fcc523abfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4792577b-8017-4eb1-a720-835baa6352fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sync for 0 documents across all models\n",
      "Full synchronization completed\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "rag_settings.init()\n",
    "rag_db.init_vector_db()\n",
    "rag_sync.full_sync()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851a5b0a-053d-4d71-acaa-e443c7ef44c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_index = rag_engines.get_model_index(\"Employee\")\n",
    "product_index = rag_engines.get_model_index(\"Product\")\n",
    "semantic_query_engine = rag_engines.get_semantic_query_engine(\"Product\")  \n",
    "sql_query_engine = rag_engines.get_sql_query_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c26810b9-aadf-4bfa-846d-34a0b2c0879e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_db ['employeeroles', 'employees', 'producttypes', 'products', 'inventoryitems', 'productinventoryrequirements']\n"
     ]
    }
   ],
   "source": [
    "print(rag_settings.VECTOR_DB_NAME, rag_settings.VECTOR_DB_TABLE_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "327c5299-5c03-443f-b825-74d5ae2a9730",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import QueryEngineTool\n",
    "\n",
    "vector_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=semantic_query_engine,\n",
    "    description=(\n",
    "        \"Useful for answering semantic questions about coffee shop operations, \"\n",
    "        \"including products, employees, inventory, and recipes\"\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f500203-7427-4c1c-9a48-55bab331a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_tool = QueryEngineTool.from_defaults(\n",
    "    query_engine=sql_query_engine,\n",
    "    description=(\n",
    "        \"Useful for translating a natural language query into a SQL query over \"\n",
    "        \"tables containing:EmployeeRole, Employee, ProductType, Product, InventoryItem, ProductInventoryRequirement.\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4dba5e-431f-4e3f-b1e9-601ab17bacd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = rag_patches.MySQLAutoVectorQueryEngine(\n",
    "    sql_tool,\n",
    "    vector_tool,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b57e35c1-899e-4a30-ad42-dc98c1d94f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.sql_join_query_engine:> Querying other query engine: The question 'how mush is an americano?' pertains to coffee shop operations, specifically about products, which is covered by choice (2).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mQuerying other query engine: The question 'how mush is an americano?' pertains to coffee shop operations, specifically about products, which is covered by choice (2).\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"how mush is an americano?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b3c8059-a3d6-49d9-9e16-8cf09a4f7abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Empty Response'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594759fe-aa4f-4a73-ad50-58d4a9e41c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.sql_join_query_engine:> Querying SQL database: The question 'Who is the bartender?' is likely to involve querying a database for employee roles, which is covered by the tables mentioned in choice (1), specifically EmployeeRole and Employee.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mQuerying SQL database: The question 'Who is the bartender?' is likely to involve querying a database for employee roles, which is covered by the tables mentioned in choice (1), specifically EmployeeRole and Employee.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:llama_index.core.indices.struct_store.sql_retriever:> Table desc str: Table 'coffeshop_employeerole' has columns: id (BIGINT), name (VARCHAR(100)), description (TEXT), .\n",
      "\n",
      "Table 'coffeshop_employee' has columns: id (BIGINT), name (VARCHAR(200)), hire_date (DATE), hourly_rate (NUMERIC(6, 2)), is_active (BOOLEAN), embedding (VECTOR(1024)), role_id (BIGINT),  and foreign keys: ['role_id'] -> coffeshop_employeerole.['id'].\n",
      "\n",
      "Table 'coffeshop_producttype' has columns: id (BIGINT), name (VARCHAR(100)), description (TEXT), embedding (VECTOR(1024)), .\n",
      "\n",
      "Table 'coffeshop_product' has columns: id (BIGINT), name (VARCHAR(200)), price (NUMERIC(6, 2)), description (TEXT), is_available (BOOLEAN), embedding (VECTOR(1024)), product_type_id (BIGINT),  and foreign keys: ['product_type_id'] -> coffeshop_producttype.['id'].\n",
      "\n",
      "Table 'coffeshop_inventoryitem' has columns: id (BIGINT), name (VARCHAR(200)), unit (VARCHAR(50)), quantity (NUMERIC(10, 2)), reorder_level (NUMERIC(10, 2)), cost_per_unit (NUMERIC(10, 2)), embedding (VECTOR(1024)), .\n",
      "\n",
      "Table 'coffeshop_productinventoryrequirement' has columns: id (BIGINT), quantity_required (NUMERIC(10, 2)), inventory_item_id (BIGINT), product_id (BIGINT),  and foreign keys: ['inventory_item_id'] -> coffeshop_inventoryitem.['id'], ['product_id'] -> coffeshop_product.['id'].\n",
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;33mSQL query: SELECT coffeshop_employee.name\n",
      "FROM coffeshop_employee\n",
      "JOIN coffeshop_employeerole ON coffeshop_employee.role_id = coffeshop_employeerole.id\n",
      "WHERE coffeshop_employeerole.name = 'Bartender' AND coffeshop_employee.is_active = TRUE\n",
      "ORDER BY coffeshop_employee.name;\n",
      "\u001b[0m\u001b[1;3;33mSQL response: Based on the query results, there is no active bartender currently listed.\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.sql_join_query_engine:> Transformed query given SQL response: Based on the SQL response, \"there is no active bartender currently listed,\" the original question \"Who is the bartender?\" has been fully answered. Therefore, the new question is:\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;34mTransformed query given SQL response: Based on the SQL response, \"there is no active bartender currently listed,\" the original question \"Who is the bartender?\" has been fully answered. Therefore, the new question is:\n",
      "\n",
      "None\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:llama_index.core.query_engine.sql_join_query_engine:> query engine response: Empty Response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;5;200mquery engine response: Empty Response\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.mistral.ai/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\n",
    "    \"Who is the bartender?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34933bf9-079f-40f7-afa4-5acc57e03985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the provided information, the response to the original question \"Who is the bartender?\" is:\n",
       "\n",
       "**There is no active bartender currently listed.**\n",
       "\n",
       "This conclusion is drawn from the SQL query response, which indicates that no active bartender is found in the database. The vector store query and response do not add any further information, as the original question has already been fully addressed by the SQL query response."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(response.response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e48da0-dd8c-48ac-bb95-3a0bc908efa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
