{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2be03cf7-e03e-48b7-ae97-a0638fcf296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sqlparse\n",
    "from tqdm.notebook import tqdm\n",
    "from typing import List, Dict, Any, Optional\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import setup\n",
    "setup.init_django()\n",
    "\n",
    "from llama_index.core import SQLDatabase\n",
    "from llama_index.core.tools import QueryEngineTool\n",
    "from llama_index.core.query_engine import NLSQLTableQueryEngine\n",
    "\n",
    "import sqlparse\n",
    "from sqlparse.tokens import Keyword, Name, Punctuation, Whitespace\n",
    "from sqlparse.sql import IdentifierList, Identifier, Comparison, Where, Parenthesis\n",
    "import difflib\n",
    "from Levenshtein import distance as levenshtein_distance\n",
    "\n",
    "from rag import (\n",
    "    db as rag_db,\n",
    "    engines as rag_engines,\n",
    "    settings as rag_settings,\n",
    "    prompts as rag_prompts,\n",
    "    patches as rag_patches,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea76d084-99c0-4972-b55e-041fb891b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_sql(sql):\n",
    "    \"\"\"Normalize SQL query for better comparison by removing extra whitespace and standardizing syntax.\"\"\"\n",
    "    if not sql or not isinstance(sql, str):\n",
    "        return \"\"\n",
    "    parsed = sqlparse.parse(sql)\n",
    "    if not parsed:\n",
    "        return \"\"\n",
    "    formatted = sqlparse.format(\n",
    "        sql,\n",
    "        keyword_case='upper',\n",
    "        identifier_case='lower',\n",
    "        strip_comments=True,\n",
    "        reindent=True,\n",
    "        reindent_aligned=True\n",
    "    )\n",
    "\n",
    "    formatted = ' '.join(formatted.split())\n",
    "    formatted = re.sub(r'[\\n\\t\\r]', ' ', formatted)  \n",
    "    formatted = re.sub(r'\\s+', ' ', formatted)      \n",
    "    formatted = re.sub(r'\\s*([(),;])\\s*', r'\\1 ', formatted)  \n",
    "    return formatted.strip()\n",
    "\n",
    "def get_table_aliases(sql):\n",
    "    \"\"\"Extract table aliases from an SQL query.\"\"\"\n",
    "    parsed = sqlparse.parse(sql)[0]\n",
    "    aliases = {}\n",
    "    \n",
    "    def extract_aliases(token):\n",
    "        if isinstance(token, Identifier):\n",
    "            if token.tokens[-1].ttype == Name and len(token.tokens) > 2:\n",
    "                for i, t in enumerate(token.tokens):\n",
    "                    if t.normalized == 'AS' and i < len(token.tokens) - 1:\n",
    "                        table_name = token.tokens[0].normalized\n",
    "                        alias = token.tokens[i+1].normalized\n",
    "                        aliases[alias.lower()] = table_name.lower()\n",
    "                        return\n",
    "                if len(token.tokens) >= 2 and token.tokens[0].ttype == Name and token.tokens[-1].ttype == Name:\n",
    "                    table_name = token.tokens[0].normalized\n",
    "                    alias = token.tokens[-1].normalized\n",
    "                    aliases[alias.lower()] = table_name.lower()\n",
    "        \n",
    "        if hasattr(token, 'tokens'):\n",
    "            for subtoken in token.tokens:\n",
    "                extract_aliases(subtoken)\n",
    "    \n",
    "    for token in parsed.tokens:\n",
    "        extract_aliases(token)\n",
    "    \n",
    "    return aliases\n",
    "\n",
    "def extract_sql_components(sql):\n",
    "    \"\"\"Extract key components from an SQL query for structured comparison.\"\"\"\n",
    "    if not sql or not isinstance(sql, str):\n",
    "        return {}\n",
    "    \n",
    "    components = {\n",
    "        'select_columns': [],\n",
    "        'from_tables': [],\n",
    "        'where_conditions': [],\n",
    "        'group_by': [],\n",
    "        'order_by': [],\n",
    "        'limit': None,\n",
    "        'joins': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        parsed = sqlparse.parse(sql)[0]\n",
    "        current_section = None\n",
    "        for token in parsed.tokens:\n",
    "            if token.ttype == Whitespace:\n",
    "                continue\n",
    "                \n",
    "            if token.ttype == Keyword:\n",
    "                if token.normalized == 'SELECT':\n",
    "                    current_section = 'select'\n",
    "                elif token.normalized == 'FROM':\n",
    "                    current_section = 'from'\n",
    "                elif token.normalized == 'WHERE':\n",
    "                    current_section = 'where'\n",
    "                elif token.normalized == 'GROUP BY':\n",
    "                    current_section = 'group_by'\n",
    "                elif token.normalized == 'ORDER BY':\n",
    "                    current_section = 'order_by'\n",
    "                elif token.normalized == 'LIMIT':\n",
    "                    current_section = 'limit'\n",
    "                elif token.normalized in ('JOIN', 'LEFT JOIN', 'RIGHT JOIN', 'INNER JOIN'):\n",
    "                    components['joins'].append(token.normalized)\n",
    "\n",
    "            if current_section == 'select' and isinstance(token, IdentifierList):\n",
    "                for identifier in token.get_identifiers():\n",
    "                    components['select_columns'].append(identifier.normalized)\n",
    "            elif current_section == 'from' and isinstance(token, IdentifierList):\n",
    "                for identifier in token.get_identifiers():\n",
    "                    components['from_tables'].append(identifier.normalized)\n",
    "            elif current_section == 'where' and isinstance(token, Where):\n",
    "                components['where_conditions'].append(token.normalized)\n",
    "\n",
    "        for token in parsed.flatten():\n",
    "            if token.ttype == Keyword and 'JOIN' in token.normalized:\n",
    "                components['joins'].append(token.normalized)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting SQL components: {str(e)}\")\n",
    "    \n",
    "    return components\n",
    "\n",
    "def calculate_sql_similarity(sql1, sql2):\n",
    "    \"\"\"Calculate similarity between two SQL queries.\"\"\"\n",
    "    norm_sql1 = normalize_sql(sql1)\n",
    "    norm_sql2 = normalize_sql(sql2)\n",
    "    \n",
    "    if not norm_sql1 or not norm_sql2:\n",
    "        return 0.0\n",
    "    \n",
    "    if norm_sql1 == norm_sql2:\n",
    "        return 1.0\n",
    "    \n",
    "    components1 = extract_sql_components(norm_sql1)\n",
    "    components2 = extract_sql_components(norm_sql2)\n",
    "    \n",
    "    string_similarity = difflib.SequenceMatcher(None, norm_sql1, norm_sql2).ratio()\n",
    "\n",
    "    max_length = max(len(norm_sql1), len(norm_sql2))\n",
    "    if max_length == 0:\n",
    "        levenshtein_similarity = 0\n",
    "    else:\n",
    "        levenshtein_similarity = 1 - (levenshtein_distance(norm_sql1, norm_sql2) / max_length)\n",
    "\n",
    "    aliases1 = get_table_aliases(norm_sql1)\n",
    "    aliases2 = get_table_aliases(norm_sql2)\n",
    "\n",
    "    similarity = (string_similarity * 0.6) + (levenshtein_similarity * 0.4)\n",
    "    \n",
    "    return min(1.0, similarity)\n",
    "\n",
    "def compare_sql_queries(predicted_sql, gold_sql, verbose=True):\n",
    "    \"\"\"Compare predicted and gold SQL queries and return structured analysis.\"\"\"\n",
    "    norm_predicted = normalize_sql(predicted_sql)\n",
    "    norm_gold = normalize_sql(gold_sql)\n",
    "    similarity = calculate_sql_similarity(predicted_sql, gold_sql)\n",
    "    pred_components = extract_sql_components(predicted_sql)\n",
    "    gold_components = extract_sql_components(gold_sql)\n",
    "    comparison = {\n",
    "        'normalized_predicted': norm_predicted,\n",
    "        'normalized_gold': norm_gold,\n",
    "        'similarity_score': similarity,\n",
    "        'exact_match': norm_predicted == norm_gold,\n",
    "        'component_differences': {}\n",
    "    }\n",
    "    for component in ['select_columns', 'from_tables', 'where_conditions', 'joins']:\n",
    "        pred_items = set(pred_components.get(component, []))\n",
    "        gold_items = set(gold_components.get(component, []))\n",
    "        \n",
    "        comparison['component_differences'][component] = {\n",
    "            'common': list(pred_items.intersection(gold_items)),\n",
    "            'only_in_predicted': list(pred_items - gold_items),\n",
    "            'only_in_gold': list(gold_items - pred_items)\n",
    "        }\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Similarity Score: {similarity:.2f}\")\n",
    "        print(f\"Exact Match: {'Yes' if comparison['exact_match'] else 'No'}\")\n",
    "        print(\"\\nNormalized Predicted SQL:\")\n",
    "        print(norm_predicted)\n",
    "        print(\"\\nNormalized Gold SQL:\")\n",
    "        print(norm_gold)\n",
    "        \n",
    "        print(\"\\nComponent Differences:\")\n",
    "        for component, diff in comparison['component_differences'].items():\n",
    "            print(f\"\\n{component.upper()}:\")\n",
    "            if diff['common']:\n",
    "                print(f\"  Common: {', '.join(diff['common'])}\")\n",
    "            if diff['only_in_predicted']:\n",
    "                print(f\"  Only in Predicted: {', '.join(diff['only_in_predicted'])}\")\n",
    "            if diff['only_in_gold']:\n",
    "                print(f\"  Only in Gold: {', '.join(diff['only_in_gold'])}\")\n",
    "    \n",
    "    return comparison\n",
    "\n",
    "def evaluate_sql_accuracy(results):\n",
    "    \"\"\"Evaluate SQL generation accuracy across all results.\"\"\"\n",
    "    if not results:\n",
    "        return {}\n",
    "    \n",
    "    metrics = {\n",
    "        'total': len(results),\n",
    "        'success_count': 0,\n",
    "        'exact_matches': 0,\n",
    "        'high_similarity': 0,  # similarity > 0.8\n",
    "        'medium_similarity': 0,  # 0.5 < similarity <= 0.8\n",
    "        'low_similarity': 0,  # similarity <= 0.5\n",
    "        'average_similarity': 0,\n",
    "        'component_accuracy': {\n",
    "            'select_columns': 0,\n",
    "            'from_tables': 0,\n",
    "            'where_conditions': 0,\n",
    "            'joins': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    total_similarity = 0\n",
    "    component_counts = {component: 0 for component in metrics['component_accuracy']}\n",
    "    \n",
    "    for result in results:\n",
    "        if not result.get('success', False) or 'predicted_sql' not in result or 'gold_sql' not in result:\n",
    "            continue\n",
    "        \n",
    "        metrics['success_count'] += 1\n",
    "        comparison = compare_sql_queries(result['predicted_sql'], result['gold_sql'], verbose=False)\n",
    "        similarity = comparison['similarity_score']\n",
    "        total_similarity += similarity\n",
    "        if comparison['exact_match']:\n",
    "            metrics['exact_matches'] += 1\n",
    "        elif similarity > 0.8:\n",
    "            metrics['high_similarity'] += 1\n",
    "        elif similarity > 0.5:\n",
    "            metrics['medium_similarity'] += 1\n",
    "        else:\n",
    "            metrics['low_similarity'] += 1\n",
    "        for component, diff in comparison['component_differences'].items():\n",
    "            component_counts[component] += 1\n",
    "            if not diff['only_in_predicted'] and not diff['only_in_gold']:\n",
    "                metrics['component_accuracy'][component] += 1\n",
    "    if metrics['success_count'] > 0:\n",
    "        metrics['average_similarity'] = total_similarity / metrics['success_count']\n",
    "        \n",
    "        for component in metrics['component_accuracy']:\n",
    "            if component_counts[component] > 0:\n",
    "                metrics['component_accuracy'][component] = metrics['component_accuracy'][component] / component_counts[component]\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def analyze_sql_complexity_with_parser(sql):\n",
    "    \"\"\"Analyze SQL complexity using sqlparse.\"\"\"\n",
    "    if not sql or not isinstance(sql, str):\n",
    "        return {'complexity': 0, 'tables': 0, 'conditions': 0, 'joins': 0, 'aggregations': 0, 'nested_queries': 0}\n",
    "    \n",
    "    try:\n",
    "        parsed = sqlparse.parse(sql)[0]\n",
    "        tables = len(re.findall(r'\\bFROM\\s+([^\\s,]+)|\\bJOIN\\s+([^\\s,]+)', sql, re.IGNORECASE))\n",
    "        joins = len(re.findall(r'\\bJOIN\\b', sql, re.IGNORECASE))\n",
    "        conditions = 0\n",
    "        for token in parsed.tokens:\n",
    "            if isinstance(token, Where):\n",
    "                conditions += len(re.findall(r'\\bAND\\b|\\bOR\\b', token.value, re.IGNORECASE)) + 1\n",
    "\n",
    "        aggregations = len(re.findall(r'\\b(COUNT|SUM|AVG|MAX|MIN|GROUP BY)\\b', sql, re.IGNORECASE))\n",
    "        nested_queries = len(re.findall(r'\\(\\s*SELECT\\b', sql, re.IGNORECASE))\n",
    "        complexity = (\n",
    "            tables * 1 + \n",
    "            joins * 2 + \n",
    "            conditions * 1.5 + \n",
    "            aggregations * 1.5 + \n",
    "            nested_queries * 3\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'complexity': complexity,\n",
    "            'tables': tables,\n",
    "            'conditions': conditions,\n",
    "            'joins': joins,\n",
    "            'aggregations': aggregations,\n",
    "            'nested_queries': nested_queries\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing SQL complexity: {str(e)}\")\n",
    "        return {'complexity': 0, 'tables': 0, 'conditions': 0, 'joins': 0, 'aggregations': 0, 'nested_queries': 0}\n",
    "\n",
    "def update_results_with_sql_analysis(results):\n",
    "    \"\"\"Update results with detailed SQL analysis.\"\"\"\n",
    "    for result in results:\n",
    "        if not result.get('success', False) or 'predicted_sql' not in result or 'gold_sql' not in result:\n",
    "            continue\n",
    "        comparison = compare_sql_queries(result['predicted_sql'], result['gold_sql'], verbose=False)\n",
    "        result['sql_similarity'] = comparison['similarity_score']\n",
    "        result['sql_exact_match'] = comparison['exact_match']\n",
    "        result['predicted_complexity'] = analyze_sql_complexity_with_parser(result['predicted_sql'])\n",
    "        result['gold_complexity'] = analyze_sql_complexity_with_parser(result['gold_sql'])\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60338609-9938-445b-afb7-692d87ea1c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpiderDatabaseManager:\n",
    "    def __init__(self, spider_dir=\"/home/harry/chatbotDjango/spider/spider_data\"):\n",
    "        self.spider_dir = spider_dir\n",
    "        self.db_dir = os.path.join(spider_dir, \"database\")\n",
    "        self.tables_file = os.path.join(spider_dir, \"tables.json\")\n",
    "        self.db_schemas = self._load_db_schemas()\n",
    "        \n",
    "    def _load_db_schemas(self):\n",
    "        with open(self.tables_file, 'r') as f:\n",
    "            return json.load(f)\n",
    "    \n",
    "    def get_db_path(self, db_id):\n",
    "        return os.path.join(self.db_dir, db_id, f\"{db_id}.sqlite\")\n",
    "    \n",
    "    def get_schema_for_db(self, db_id):\n",
    "        for db_schema in self.db_schemas:\n",
    "            if db_schema['db_id'] == db_id:\n",
    "                return db_schema\n",
    "        return None\n",
    "    \n",
    "    def get_all_db_ids(self):\n",
    "        return [db_schema['db_id'] for db_schema in self.db_schemas]\n",
    "    \n",
    "    def get_sqlalchemy_engine(self, db_id):\n",
    "        db_path = self.get_db_path(db_id)\n",
    "        return create_engine(f\"sqlite:///{db_path}\")\n",
    "    \n",
    "    def get_table_names(self, db_id):\n",
    "        schema = self.get_schema_for_db(db_id)\n",
    "        if schema and 'table_names_original' in schema:\n",
    "            tables = schema['table_names_original']\n",
    "            return [t['table_name'] if isinstance(t, dict) else str(t) for t in tables]\n",
    "        return []\n",
    "    \n",
    "    def get_llama_index_database(self, db_id):\n",
    "        engine = self.get_sqlalchemy_engine(db_id)\n",
    "        table_names = self.get_table_names(db_id)\n",
    "        return SQLDatabase(engine, include_tables=table_names)\n",
    "\n",
    "spider_manager = SpiderDatabaseManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "958fa294-e2f9-432e-8b3f-5488f1b1fe4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1034 Spider dev examples\n"
     ]
    }
   ],
   "source": [
    "SPIDER_DIR = \"/home/harry/chatbotDjango/spider/spider_data\"\n",
    "\n",
    "def load_spider_data(split=\"dev\"):\n",
    "    file_path = os.path.join(SPIDER_DIR, f\"{split}.json\")\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "try:\n",
    "    spider_dev = load_spider_data(\"dev\")\n",
    "    print(f\"Loaded {len(spider_dev)} Spider dev examples\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {str(e)}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d067c19-d772-49c5-8846-fe39d9f6ef93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spider_sql_query_engine(db_id):\n",
    "    sql_database = spider_manager.get_llama_index_database(db_id)\n",
    "    table_names = spider_manager.get_table_names(db_id)\n",
    "    text_to_sql_prompt = rag_prompts.custom_text_to_sql_prompt\n",
    "    text_to_sql_prompt.template = text_to_sql_prompt.template.replace(\n",
    "        \"{dialect} PostgreSQL\", \"SQLite\"\n",
    "    )\n",
    "    \n",
    "    return NLSQLTableQueryEngine(\n",
    "        sql_database=sql_database,\n",
    "        tables=table_names,\n",
    "        response_synthesis_prompt=rag_prompts.custom_sql_response_synthesis_prompt,\n",
    "        text_to_sql_prompt=text_to_sql_prompt\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4b5117c-b796-48a2-b5e4-25f433c776e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "LAST_API_CALL_TIME = 0\n",
    "MAX_RETRIES = 3\n",
    "\n",
    "def api_call_with_retry(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        global LAST_API_CALL_TIME, MAX_RETRIES\n",
    "        retries = 0\n",
    "        \n",
    "        while retries <= MAX_RETRIES:\n",
    "            elapsed = time.time() - LAST_API_CALL_TIME\n",
    "            if elapsed < 1:  # 1 second between calls\n",
    "                time.sleep(1 - elapsed)\n",
    "            \n",
    "            try:\n",
    "                result = func(*args, **kwargs)\n",
    "                LAST_API_CALL_TIME = time.time()\n",
    "                return result\n",
    "            except Exception as e:\n",
    "                if \"rate limit\" in str(e).lower():\n",
    "                    retries += 1\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    raise\n",
    "        raise RuntimeError(f\"API call failed after {MAX_RETRIES} retries\")\n",
    "    return wrapper\n",
    "\n",
    "@api_call_with_retry\n",
    "def translate_to_farsi(text):\n",
    "    print(f\"\\nTranslating: {text}\")\n",
    "    prompt = f\"Translate English to Farsi. Only return translation:\\n{text}\"\n",
    "    response = rag_settings.Settings.llm.complete(prompt)\n",
    "    print(f\"Translation result: {response.text}\")  \n",
    "    return response.text.strip()\n",
    "\n",
    "@api_call_with_retry\n",
    "def execute_query(query_engine, query_text):\n",
    "    return query_engine.query(query_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cab40f5b-db2a-4063-9533-ce4c14c6b6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def evaluate_on_spider_sample(sample_size=10, use_farsi=False, random_seed=42):\n",
    "    \"\"\"Evaluate SQL generation performance on a sample of Spider dev examples.\"\"\"\n",
    "    random.seed(random_seed)\n",
    "    sample = random.sample(spider_dev, sample_size)\n",
    "    results = []\n",
    "\n",
    "    for example in tqdm(sample, desc=\"Evaluating Spider examples\"):\n",
    "        db_id = example['db_id']\n",
    "        question = example['question']\n",
    "        gold_sql = example['query']\n",
    "\n",
    "        try:\n",
    "            if use_farsi:\n",
    "                question = translate_to_farsi(question)\n",
    "            query_engine = create_spider_sql_query_engine(db_id)\n",
    "            response = execute_query(query_engine, question)\n",
    "            predicted_sql = str(response.metadata['sql_query']).strip()\n",
    "\n",
    "            results.append({\n",
    "                'db_id': db_id,\n",
    "                'question': example['question'],  \n",
    "                'predicted_sql': predicted_sql,\n",
    "                'gold_sql': gold_sql,\n",
    "                'success': True,\n",
    "                'error': None\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            results.append({\n",
    "                'db_id': db_id,\n",
    "                'question': example['question'],\n",
    "                'predicted_sql': None,\n",
    "                'gold_sql': gold_sql,\n",
    "                'success': False,\n",
    "                'error': str(e)\n",
    "            })\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcb57acc-ba34-4fe2-ad04-c3beffb4d245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_extended_evaluation(sample_size=1, use_farsi=False, random_seed=42):\n",
    "    \"\"\"Run extended evaluation with SQL parser comparison\"\"\"\n",
    "    results = evaluate_on_spider_sample(sample_size=sample_size, use_farsi=use_farsi, random_seed=random_seed)\n",
    "    print(f\"\\nAdding SQL parser analysis to {len(results)} results...\")\n",
    "    updated_results = update_results_with_sql_analysis(results)\n",
    "    accuracy_metrics = evaluate_sql_accuracy(updated_results)\n",
    "    print(\"\\n===== SQL Accuracy Metrics =====\")\n",
    "    print(f\"Total queries evaluated: {accuracy_metrics['total']}\")\n",
    "    print(f\"Successful queries: {accuracy_metrics['success_count']}\")\n",
    "    print(f\"Exact SQL matches: {accuracy_metrics['exact_matches']} ({accuracy_metrics['exact_matches']/accuracy_metrics['success_count']*100:.2f}% of successful queries)\")\n",
    "    print(f\"High similarity (>0.8): {accuracy_metrics['high_similarity']} ({accuracy_metrics['high_similarity']/accuracy_metrics['success_count']*100:.2f}% of successful queries)\")\n",
    "    print(f\"Medium similarity (0.5-0.8): {accuracy_metrics['medium_similarity']} ({accuracy_metrics['medium_similarity']/accuracy_metrics['success_count']*100:.2f}% of successful queries)\")\n",
    "    print(f\"Low similarity (<0.5): {accuracy_metrics['low_similarity']} ({accuracy_metrics['low_similarity']/accuracy_metrics['success_count']*100:.2f}% of successful queries)\")\n",
    "    print(f\"Average similarity score: {accuracy_metrics['average_similarity']:.4f}\")\n",
    "    \n",
    "    print(\"\\nComponent-wise accuracy:\")\n",
    "    for component, accuracy in accuracy_metrics['component_accuracy'].items():\n",
    "        print(f\"  {component}: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    display_sql_analysis_visualizations(updated_results)\n",
    "    \n",
    "    return updated_results\n",
    "\n",
    "def display_sql_analysis_visualizations(results):\n",
    "    \"\"\"Create and display visualizations for SQL analysis results\"\"\"\n",
    "    successful_results = [r for r in results if r.get('success', False) and 'sql_similarity' in r]\n",
    "    \n",
    "    if not successful_results:\n",
    "        print(\"No successful results with SQL similarity data available for visualization\")\n",
    "        return\n",
    "    df = pd.DataFrame(successful_results)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(df['sql_similarity'], bins=10, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title('Distribution of SQL Similarity Scores')\n",
    "    plt.xlabel('Similarity Score')\n",
    "    plt.ylabel('Number of Queries')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.show()\n",
    "\n",
    "    if 'predicted_complexity' in df.columns:\n",
    "        pred_complexity = pd.DataFrame([r['predicted_complexity'] for r in successful_results])\n",
    "        gold_complexity = pd.DataFrame([r['gold_complexity'] for r in successful_results])\n",
    "        avg_pred = pred_complexity.mean()\n",
    "        avg_gold = gold_complexity.mean()\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        metrics = ['tables', 'conditions', 'joins', 'aggregations', 'nested_queries']\n",
    "        x = np.arange(len(metrics))\n",
    "        width = 0.35\n",
    "        plt.bar(x - width/2, [avg_pred[m] for m in metrics], width, label='Predicted SQL')\n",
    "        plt.bar(x + width/2, [avg_gold[m] for m in metrics], width, label='Gold SQL')\n",
    "        plt.xlabel('Metrics')\n",
    "        plt.ylabel('Average Count')\n",
    "        plt.title('SQL Complexity Comparison')\n",
    "        plt.xticks(x, [m.capitalize() for m in metrics])\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(pred_complexity['complexity'], df['sql_similarity'], alpha=0.7)\n",
    "        plt.title('Correlation between Query Complexity and Similarity Score')\n",
    "        plt.xlabel('Query Complexity')\n",
    "        plt.ylabel('Similarity Score')\n",
    "        plt.grid(alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    if 'language' in df.columns and len(df['language'].unique()) > 1:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        similarity_by_lang = df.groupby('language')['sql_similarity'].agg(['mean', 'std', 'count'])\n",
    "        similarity_by_lang.columns = ['Mean Similarity', 'Std Dev', 'Count']\n",
    "        plt.bar(similarity_by_lang.index, similarity_by_lang['Mean Similarity'], \n",
    "                yerr=similarity_by_lang['Std Dev'], alpha=0.7, \n",
    "                capsize=10, color=['blue', 'green'])\n",
    "        plt.title('SQL Similarity by Language')\n",
    "        plt.xlabel('Language')\n",
    "        plt.ylabel('Average Similarity Score')\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def detailed_sql_comparison_example(results, num_examples=5):\n",
    "    \"\"\"Show detailed examples of SQL comparisons for a single language\"\"\"\n",
    "    examples = [r for r in results if r.get('success', False) and 'sql_similarity' in r]\n",
    "    \n",
    "    if not examples:\n",
    "        print(\"No suitable examples for detailed SQL comparison\")\n",
    "        return\n",
    "    examples.sort(key=lambda x: x['sql_similarity'])\n",
    "    \n",
    "    print(f\"\\n===== Detailed SQL Comparison Examples ({len(examples)}) =====\")\n",
    "    \n",
    "    for i, example in enumerate(examples[:num_examples]):\n",
    "        print(f\"\\nExample {i+1} (Similarity: {example['sql_similarity']:.4f})\")\n",
    "        print(f\"Database: {example['db_id']}\")\n",
    "        print(f\"Question: {example['question']}\")  # Original English question\n",
    "        print(f\"Translated Question: {translate_to_farsi(example['question'])}\")  # Add if you want Farsi display\n",
    "        print(f\"\\nSimilarity Score: {example['sql_similarity']:.2f}\")\n",
    "        print(f\"Exact Match: {'Yes' if example['sql_exact_match'] else 'No'}\")\n",
    "        print(\"\\nNormalized Predicted SQL:\")\n",
    "        print(example['predicted_sql'])\n",
    "        print(\"\\nNormalized Gold SQL:\")\n",
    "        print(example['gold_sql'])\n",
    "        print(\"\\nComponent Differences:\")\n",
    "        comparison = compare_sql_queries(example['predicted_sql'], example['gold_sql'], verbose=False)\n",
    "        for component, diff in comparison['component_differences'].items():\n",
    "            print(f\"\\n{component.upper()}:\")\n",
    "            if diff['only_in_predicted']:\n",
    "                print(f\"  Extra in Predicted: {', '.join(diff['only_in_predicted'])}\")\n",
    "            if diff['only_in_gold']:\n",
    "                print(f\"  Missing from Predicted: {', '.join(diff['only_in_gold'])}\")\n",
    "        \n",
    "        print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c3ec60-7bbb-4edb-b265-1d37bbd44fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_result = 50\n",
    "\n",
    "print(\"Running English evaluation with SQL parser...\")\n",
    "english_extended_results = run_extended_evaluation(sample_size=num_result, use_farsi=False)\n",
    "\n",
    "detailed_sql_comparison_example(english_extended_results, num_examples=num_result)\n",
    "\n",
    "print(\"Running Farsi evaluation with SQL parser...\")\n",
    "farsi_extended_results = run_extended_evaluation(sample_size=num_result, use_farsi=True)\n",
    "\n",
    "detailed_sql_comparison_example(farsi_extended_results, num_examples=num_result)\n",
    "\n",
    "print(\"\\n===== English vs Farsi SQL Generation Comparison =====\")\n",
    "\n",
    "for r in english_extended_results:\n",
    "    r['language'] = 'English'\n",
    "for r in farsi_extended_results:\n",
    "    r['language'] = 'Farsi'\n",
    "\n",
    "all_results = english_extended_results + farsi_extended_results\n",
    "df_combined = pd.DataFrame([r for r in all_results if r.get('success', False) and 'sql_similarity' in r])\n",
    "\n",
    "if not df_combined.empty:\n",
    "    metrics_by_lang = df_combined.groupby('language').agg({\n",
    "        'sql_similarity': ['mean', 'std', 'count'],\n",
    "        'sql_exact_match': 'mean'\n",
    "    })\n",
    "    \n",
    "    print(\"\\nSQL Similarity Metrics by Language:\")\n",
    "    print(metrics_by_lang)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    lang_means = df_combined.groupby('language')['sql_similarity'].mean()\n",
    "    lang_stds = df_combined.groupby('language')['sql_similarity'].std()\n",
    "    plt.bar(lang_means.index, lang_means, yerr=lang_stds, capsize=10, alpha=0.7)\n",
    "    plt.title('Average SQL Similarity Score')\n",
    "    plt.xlabel('Language')\n",
    "    plt.ylabel('Similarity Score')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    exact_match_rate = df_combined.groupby('language')['sql_exact_match'].mean()\n",
    "    plt.bar(exact_match_rate.index, exact_match_rate, alpha=0.7)\n",
    "    plt.title('SQL Exact Match Rate')\n",
    "    plt.xlabel('Language')\n",
    "    plt.ylabel('Exact Match Rate')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    english_dict = {r['question']: r for r in english_extended_results if r.get('success', False)}\n",
    "    farsi_dict = {r['question']: r for r in farsi_extended_results if r.get('success', False)}\n",
    "    \n",
    "    common_questions = set(english_dict.keys()) & set(farsi_dict.keys())\n",
    "    \n",
    "    if common_questions:\n",
    "        print(f\"\\nFound {len(common_questions)} questions tested in both languages with successful SQL generation\")\n",
    "        \n",
    "        direct_comparison = []\n",
    "        for question in common_questions:\n",
    "            direct_comparison.append({\n",
    "                'question': question,\n",
    "                'en_similarity': english_dict[question].get('sql_similarity', 0),\n",
    "                'fa_similarity': farsi_dict[question].get('sql_similarity', 0),\n",
    "                'en_exact': english_dict[question].get('sql_exact_match', False),\n",
    "                'fa_exact': farsi_dict[question].get('sql_exact_match', False),\n",
    "            })\n",
    "        \n",
    "        df_direct = pd.DataFrame(direct_comparison)\n",
    "        \n",
    "        print(\"\\nDirect comparison of SQL accuracy for same questions:\")\n",
    "        print(df_direct[['en_similarity', 'fa_similarity', 'en_exact', 'fa_exact']].mean())\n",
    "        \n",
    "        # Paired t-test to check for statistical significance\n",
    "        from scipy import stats\n",
    "        t_stat, p_val = stats.ttest_rel(df_direct['en_similarity'], df_direct['fa_similarity'])\n",
    "        \n",
    "        print(f\"\\nPaired t-test for SQL similarity: t={t_stat:.4f}, p={p_val:.4f}\")\n",
    "        if p_val < 0.05:\n",
    "            print(\"The difference in SQL similarity between English and Farsi is statistically significant.\")\n",
    "        else:\n",
    "            print(\"No statistically significant difference in SQL similarity between English and Farsi.\")\n",
    "else:\n",
    "    print(\"Not enough data for English vs Farsi comparison\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c937ac-699d-4298-98ef-5b6959041b39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
